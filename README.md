# Path_evaluation

## Overview

This package is used to evaluate multi-paths generated by swarm algorithms in terms of  flight distance, flight time and collision times to static obstacles and to other agents. This package supports different types of path input and the implementation of inherited classes supports the user to develop their evaluators easily. Users can see what the paths look like and whether there is a collision between each pair of paths in rviz.

![](/home/zuzu/Documents/Docker/ego_planner_swarm/src/experiments/10.25/pict/ego_circle.png)



## Installation

```bash
sudo apt-get install libarmadillo-dev
git clone https://github.com/ZJU-FAST-Lab/ego-planner.git
cd 
catkin_make
source devel/setup.bash
roslaunch ego_planner simple_run.launch
```



## Benchmark

We compare our algorithm **EGO-Swarm** with the following three different swarm algorithms:

- Distributed Optimal Reciprocal Collision Avoidance (**DORCA**, paper, [code](https://github.com/harish1696/d-orca))
- Distributed model predictive control (**DMPC**, [paper](https://arxiv.org/abs/1809.04230), [code](https://github.com/carlosluisg/multiagent_planning))
- Relative Bernstein Polynomial approach (**RBP**, [paper](https://arxiv.org/abs/1909.10219), [code](https://github.com/qwerty35/swarm_simulator))

We basically used the parameters the author recommended in their papers, except for the maximum velocity and maximum acceleration.



## Usage

We have implemented inherited classes to support different algorithms to try not to modify the source code as possible as we could. Users can distinguish the swarm algorithms corresponding to the classes by their names. Users can realize fast switching between different swarm algorithms by launching different launch files.

```bash
launch
├── demo.rviz
├── dmpc.launch
├── dorca.launch
├── ego.launch
└── rbp.launch
```



Nevertheless, in order to make the evaluation program run automatically, it is inevitable to make modifications to the source code, especially in terms of planning time, which can only be obtained from the source code. At the same time, we also need the start and end signals of the online algorithms to indicate the start and end of the evaluation. Below I will explain how to evaluate different algorithms briefly.



**DORCA**

DORCA uses gazebo as the simulator and the odometry of the drones  are packed as one topic in format gazebo_msgs::ModelStates published by gazebo.  It's important to notice that the odometry of agents are followed by the some models in environment when you try to decode the ModelStates topic to get the odometry of the each agent. An example of what the contents are in the topic is listed below.

```
name: [ground_plane, iris_1, ..., ...]
pose: 
  - 
    position: 
      x: 0.0
      y: 0.0
      z: 0.0
    orientation: 
      x: 0.0
      y: 0.0
      z: 0.0
      w: 1.0
  - 
    position: 
      x: -1.46428436561
      y: -1.21966047751
      z: 1.326538828
    orientation: 
      x: 0.0297794532925
      y: -0.0557362565521
      z: 0.010730963121
      w: 0.997943635832
  - 
	...
twist: 
  - 
    linear: 
      x: 0.0
      y: 0.0
      z: 0.0
    angular: 
      x: 0.0
      y: 0.0
      z: 0.0
  - 
    linear: 
      x: -0.773939569784
      y: -0.416228256679
      z: 0.110915895951
    angular: 
      x: 0.00700660478464
      y: 0.00296595010337
      z: 0.000380869485537
  - 
    ...
---
```

Another thing  , the process of the execution is two-step. The first step is that all drones are lifted to a predefined height, then the user-defined task is ongoing. So a start signal needs to be published to tell the evaluation node after the first step is completed. 



### RBP

Rbp is an offline approach, every drone executes trajectory after the whole trajectory has been planed. Topic publish is managed by a class rbp_publisher, it will publish the whole path as the `nav_msgs::Path` format all the time. In order to calculate the path length and executing time, a signal indicating that drone has reached the goal is needed, but there is no such function implemented in rbp simulation. A easy solution is that after all the drones have reached their goals, launch the evaluation node because the evaluation node will subscribe the complete path only once and perform evaluation process on the whole path and then write results to local file.



### Dmpc

**Dmpc** is an offline planner and it stores generated paths in local files. You need to make sure that the param `trajectroy_fn`  in demo.launch is the right path to the trajectory file.



### Ego-swarm



## Scripts

In order to quickly generate a specified number of agents and starting and ending points, this package provides some python scripts to generate launch files quickly. Users should modify the path of the exported file in the script file. 

```
scripts
├── dorca.py
├── ego_obs.py
├── ego.py
└── ego_scalability.py
```

